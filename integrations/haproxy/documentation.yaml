exporter_type: sidecar
app_name_short: HAProxy
app_name: {{app_name_short}}
app_site_name: HAProxy
app_site_url: https://www.haproxy.com/
exporter_name: the HAProxy exporter
exporter_pkg_name: haproxy_exporter
exporter_repo_url: https://github.com/prometheus/haproxy_exporter
dashboard_available: true
minimum_exporter_version: v0.13.0
multiple_dashboards: false
dashboard_display_name: {{app_name_short}} Prometheus Overview
config_mods: |
  apiVersion: v1
  kind: ConfigMap
  metadata:
    name: haproxy
  data:
    haproxy.cfg: |
  +   frontend stats
  +     mode http
  +     bind *:8404
  +     stats enable
  +     stats uri /stats
  ---
  apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: haproxy
  spec:
    selector:
      matchLabels:
  +     app.kubernetes.io/name: haproxy
    template:
      metadata:
        labels:
  +       app.kubernetes.io/name: haproxy
      spec:
        containers:
  +     - name: exporter
  +       image: quay.io/prometheus/haproxy-exporter:v0.13.0
  +       args:
  +       - --haproxy.scrape-uri=http://localhost:8404/stats?stats;csv
  +       ports:
  +       - containerPort: 9101
  +         name: prometheus
        - name: haproxy
          image: haproxy:2.3
          ports:
  +       - containerPort: 8404
  +         name: stats
          volumeMounts:
          - mountPath: /usr/local/etc/haproxy/haproxy.cfg
            subPath: haproxy.cfg
            name: haproxy
        volumes:
        - name: haproxy
          configMap:
            name: haproxy
            items:
            - key: haproxy.cfg
              path: haproxy.cfg
additional_install_info: |
  The recommended changes in <code>haproxy.cfg</code> defines a frontend with the "stats enable" directive 
  and enables the {{app_name_short}} stats page. This frontend can be scraped by {{exporter_pkg_name}}.
  For more information, see [Exploring the HAProxy Stats page](https://www.haproxy.com/blog/exploring-the-haproxy-stats-page/){:class=external}.
podmonitoring_config: |
  apiVersion: monitoring.googleapis.com/v1
  kind: PodMonitoring
  metadata:
    name: haproxy
    labels:
      app.kubernetes.io/name: haproxy
      app.kubernetes.io/part-of: google-cloud-managed-prometheus
  spec:
    endpoints:
    - port: prometheus
      scheme: http
      interval: 30s
      path: /metrics
    selector:
      matchLabels:
        app.kubernetes.io/name: haproxy
sample_promql_query: up{job="haproxy", cluster="{{cluster_name}}", namespace="{{namespace_name}}"}
alerts_config: |
  apiVersion: monitoring.googleapis.com/v1
  kind: Rules
  metadata:
    name: haproxy-rules
    labels:
      app.kubernetes.io/component: rules
      app.kubernetes.io/name: haproxy-rules
      app.kubernetes.io/part-of: google-cloud-managed-prometheus
  spec:
    groups:
    - name: haproxy
      interval: 30s
      rules:
      - alert: HAProxyDown
        annotations:
          description: |-
            HAProxy instance is down 
              VALUE = {{ $value }}
              LABELS: {{ $labels }}
          summary: HAProxy down (instance {{ $labels.instance }})
        expr: haproxy_server_up{job="haproxy"} == 0
        for: 5m
        labels:
          severity: critical
      - alert: HAProxyTooManyConnections
        annotations:
          description: |-
            HAProxy instance has too many connections
              VALUE = {{ $value }}
              LABELS: {{ $labels }}
          summary: HAProxy too many connections (instance {{ $labels.instance }})
        expr: haproxy_frontend_current_sessions{job="haproxy"} / haproxy_frontend_limit_sessions{job="haproxy"} * 100 > 90
        for: 5m
        labels:
          severity: warning
additional_alert_info: You can adjust the alert thresholds to suit your application.
